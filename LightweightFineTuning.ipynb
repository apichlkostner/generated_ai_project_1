{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c4322b",
   "metadata": {},
   "source": [
    "### Load the datasdet dair-air/emotion and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506ec15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "i want to feel like i m reading something worthwhile : 1\n",
      "i have a feeling this month is going to have some damn cool things in store : 1\n",
      "im happy to say im feeling so much more creative than i have in a long time : 1\n",
      "i don t want to go all very special episode of blossom on you but i am feeling a little melancholy about the final episode of rock : 0\n",
      "i feel heartbroken again i feel dead inside lost angry at myself : 0\n",
      "i understand the feeling so i wouldnt be shocked : 5\n",
      "i inquire incheswhyinches are people relocating droves about what they feel is security in precious metal : 1\n",
      "i feel wonderful monroe said upon the launch of her company im incorporated : 1\n",
      "i stared up at him amazed by the feeling and as equally amazed that nothing else was happening : 5\n",
      "im feeling today as about how i liked the books when i read them if i made this list tomorrow it would be different : 2\n",
      "\n",
      "Labels: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# print some random featues and the labels\n",
    "print(\"Features:\")\n",
    "indices = random.sample(range(len(ds[\"train\"])), 10)\n",
    "for i in indices:\n",
    "    print(\"{} : {}\".format(ds[\"train\"]['text'][i], ds[\"train\"]['label'][i]))\n",
    "\n",
    "print(\"\\nLabels: {}\".format(ds[\"train\"].features[\"label\"].names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
      "{'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}\n"
     ]
    }
   ],
   "source": [
    "# create data structures for further processing\n",
    "\n",
    "# names of the splits\n",
    "splits=list(ds.keys())\n",
    "# number of classes\n",
    "num_classes=len(ds[\"train\"].features[\"label\"].names)\n",
    "\n",
    "# Dictionairies to translate between label string and label number\n",
    "id2label = dict(zip(range(num_classes), ds['train'].features['label'].names))\n",
    "label2id = dict(zip(ds['train'].features['label'].names, range(num_classes)))\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d125f7",
   "metadata": {},
   "source": [
    "Create a base model with added padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd66c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if hasattr(torch, \"accelerator\") else \"cuda\"\n",
    "\n",
    "# Create a base model variant with classification head\n",
    "def create_base_model(model_id):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_id, \n",
    "        num_labels=num_classes,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        device_map=device)\n",
    "    if model.config.pad_token_id is None:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Use GPT-2 as a small base model\n",
    "model_id = \"openai-community/gpt2\"\n",
    "model = create_base_model(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Add tokens to the dataset\n",
    "tokenized_ds = {}\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(\n",
    "        lambda x: tokenizer(x[\"text\"], truncation=True), batched=True\n",
    "    )\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add the padding token which is missing in GPT-2\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# metric function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [640/640 00:58, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.311079</td>\n",
       "      <td>0.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.245872</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.229976</td>\n",
       "      <td>0.542500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.311100</td>\n",
       "      <td>1.223381</td>\n",
       "      <td>0.546500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=640, training_loss=1.2824213027954101, metrics={'train_runtime': 59.2461, 'train_samples_per_second': 1080.24, 'train_steps_per_second': 10.802, 'total_flos': 1848843351244800.0, 'train_loss': 1.2824213027954101, 'epoch': 4.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import os\n",
    "\n",
    "temp_path = \"/tmp\"\n",
    "save_path = \"./data\"\n",
    "\n",
    "model_name = \"gpt2_classification\"\n",
    "checkpoint_dir = os.path.join(temp_path, model_name)\n",
    "save_dir_base = os.path.join(save_path, model_name)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=checkpoint_dir,\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=100,\n",
    "        per_device_eval_batch_size=100,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2233811616897583, 'eval_accuracy': 0.5465, 'eval_runtime': 1.3104, 'eval_samples_per_second': 1526.301, 'eval_steps_per_second': 15.263, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "original_performance=trainer.evaluate()\n",
    "print(original_performance)\n",
    "\n",
    "model.save_pretrained(save_dir_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 594,432 || all params: 125,038,848 || trainable%: 0.4754\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "# Use Lora for PEFT\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    fan_in_fan_out=True,\n",
    ")\n",
    "\n",
    "# create PEFT model, use a fresh pretrained base model\n",
    "model_lora = get_peft_model(create_base_model(model_id), peft_config)\n",
    "model_lora.print_trainable_parameters()\n",
    "\n",
    "model_name = \"gpt2_classification_lora\"\n",
    "checkpoint_dir = os.path.join(temp_path, model_name)\n",
    "save_dir = os.path.join(save_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [640/640 01:10, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221460</td>\n",
       "      <td>0.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164348</td>\n",
       "      <td>0.929500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.148877</td>\n",
       "      <td>0.923500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=640, training_loss=0.3104581475257874, metrics={'train_runtime': 70.4535, 'train_samples_per_second': 908.401, 'train_steps_per_second': 9.084, 'total_flos': 1861763687424000.0, 'train_loss': 0.3104581475257874, 'epoch': 4.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_lora = Trainer(\n",
    "    model=model_lora,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=checkpoint_dir,\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=100,\n",
    "        per_device_eval_batch_size=100,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_lora.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ⚠️ IMPORTANT ⚠️\n",
    "\n",
    "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_lora.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModelForTokenClassification\n",
    "\n",
    "model_id = \"openai-community/gpt2\"\n",
    "model_base = create_base_model(model_id)\n",
    "\n",
    "model_loaded = PeftModelForTokenClassification.from_pretrained(model_base, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_evaluate = Trainer(\n",
    "    model=model_loaded,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis_lora_evaluate\",\n",
    "        per_device_train_batch_size=100,\n",
    "        per_device_eval_batch_size=100,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "    ),\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "fine_tuned_performance=trainer_evaluate.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model:   {'eval_loss': 1.2233811616897583, 'eval_accuracy': 0.5465, 'eval_runtime': 1.3104, 'eval_samples_per_second': 1526.301, 'eval_steps_per_second': 15.263, 'epoch': 4.0}\n",
      "Fine-Tuned Model: {'eval_loss': 0.12743067741394043, 'eval_model_preparation_time': 0.0019, 'eval_accuracy': 0.925, 'eval_runtime': 0.8968, 'eval_samples_per_second': 2230.054, 'eval_steps_per_second': 22.301}\n",
      "Original Model accurcy:    0.5465\n",
      "Fine-Tuned Model accurcy:  0.925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Original Model:  \", original_performance)\n",
    "print(\"Fine-Tuned Model:\", fine_tuned_performance)\n",
    "\n",
    "print(\"Original Model accurcy:   \", original_performance['eval_accuracy'])\n",
    "print(\"Fine-Tuned Model accurcy: \", fine_tuned_performance['eval_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e46c59",
   "metadata": {},
   "source": [
    "### Use different Quantization: QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c5c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 594,432 || all params: 125,038,848 || trainable%: 0.4754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 01:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250119</td>\n",
       "      <td>0.909000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.159906</td>\n",
       "      <td>0.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.133373</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.123560</td>\n",
       "      <td>0.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.119329</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_id = \"openai-community/gpt2\"\n",
    "temp_path = \"/tmp\"\n",
    "save_path = \"./data\"\n",
    "\n",
    "model_name = \"gpt2_classification_4bit_lora\"\n",
    "checkpoint_dir = os.path.join(temp_path, model_name)\n",
    "save_dir_base = os.path.join(save_path, model_name)\n",
    "\n",
    "model_id = \"openai-community/gpt2\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "model4b = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=num_classes,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    torch_dtype=\"auto\")\n",
    "\n",
    "model4b.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "for param in model4b.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# peft model\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    fan_in_fan_out=True,\n",
    ")\n",
    "\n",
    "model4bl = get_peft_model(model4b, peft_config)\n",
    "model4bl.print_trainable_parameters()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model4bl,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=checkpoint_dir,\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=100,\n",
    "        per_device_eval_batch_size=100,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        fp16=True\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "validation_lora_q4 = trainer.evaluate()\n",
    "#model4bl.save_pretrained(save_dire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47c674ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model accuracy:          0.543\n",
      "Fine-Tuned Model accuracy:        0.9285\n",
      "Fine-Tuned Model 4 bit accuracy:  0.9285\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Model accuracy:         \", original_performance['eval_accuracy'])\n",
    "print(\"Fine-Tuned Model accuracy:       \", fine_tuned_performance['eval_accuracy'])\n",
    "print(\"Fine-Tuned Model 4 bit accuracy: \", validation_lora_q4['eval_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88eb0c",
   "metadata": {},
   "source": [
    "### Experiment with different LoRA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b74db434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModelForTokenClassification, LoraConfig, TaskType, get_peft_model\n",
    "import pandas as pd\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def create_lora_config(r, lora_alpha, lora_dropout):\n",
    "    peft_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        task_type=TaskType.TOKEN_CLS,\n",
    "        fan_in_fan_out=True,\n",
    "    )\n",
    "\n",
    "    return peft_config\n",
    "\n",
    "def create_lora_model(peft_config):\n",
    "    model_base = create_base_model(model_id)\n",
    "    model_lora = get_peft_model(model_base, peft_config)\n",
    "\n",
    "    return model_lora\n",
    "    \n",
    "def create_trainer(model, learning_rate, weight_decay):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir='/tmp',\n",
    "            per_device_train_batch_size=50,\n",
    "            per_device_eval_batch_size=50,\n",
    "            num_train_epochs=4,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "        ),\n",
    "        train_dataset=tokenized_ds[\"train\"],\n",
    "        eval_dataset=tokenized_ds[\"test\"],\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    return trainer\n",
    "\n",
    "def evaluate_model(model):\n",
    "    eval = model.evaluate()\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35e53326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.203967</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.164355</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.152113</td>\n",
       "      <td>0.929500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.131185</td>\n",
       "      <td>0.931000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1          0.002          0.01     0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=4, alpha=8 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.218007</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.167399</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.131540</td>\n",
       "      <td>0.928000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1          0.002          0.01     0.931\n",
      "1  4      8      0.1          0.002          0.01     0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=2, alpha=4 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243588</td>\n",
       "      <td>0.911500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.180413</td>\n",
       "      <td>0.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.171336</td>\n",
       "      <td>0.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.148653</td>\n",
       "      <td>0.921500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1          0.002          0.01    0.9310\n",
      "1  4      8      0.1          0.002          0.01    0.9280\n",
      "2  2      4      0.1          0.002          0.01    0.9215\n"
     ]
    }
   ],
   "source": [
    "for r in [8, 4, 2]:\n",
    "    dropout = 0.1\n",
    "    learning_rate = 2e-3\n",
    "    weight_decay = 0.01\n",
    "    alpha = 2 * r\n",
    "    config = create_lora_config(r, alpha, dropout)\n",
    "    model = create_lora_model(config)\n",
    "    trainer = create_trainer(model, learning_rate, weight_decay)\n",
    "\n",
    "    print(\"Start training a model with R={}, alpha={} droptout={}\".format(r, alpha, dropout))\n",
    "\n",
    "    trainer.train()\n",
    "    eval = trainer.evaluate()\n",
    "\n",
    "    accuracy = eval['eval_accuracy']\n",
    "    results.append({'r': r, 'alpha': alpha, 'dropout': dropout, 'learning_rate':learning_rate, 'weight_decay': weight_decay, 'accuracy': accuracy})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ad3466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.514827</td>\n",
       "      <td>0.806500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.004500</td>\n",
       "      <td>0.336314</td>\n",
       "      <td>0.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.004500</td>\n",
       "      <td>0.292412</td>\n",
       "      <td>0.893500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.268815</td>\n",
       "      <td>0.899000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1         0.0020          0.01    0.9310\n",
      "1  4      8      0.1         0.0020          0.01    0.9280\n",
      "2  2      4      0.1         0.0020          0.01    0.9215\n",
      "3  8     16      0.1         0.0002          0.01    0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208435</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.148615</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.121173</td>\n",
       "      <td>0.930500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1         0.0020          0.01    0.9310\n",
      "1  4      8      0.1         0.0020          0.01    0.9280\n",
      "2  2      4      0.1         0.0020          0.01    0.9215\n",
      "3  8     16      0.1         0.0002          0.01    0.8990\n",
      "4  8     16      0.1         0.0020          0.01    0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.046261</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.357200</td>\n",
       "      <td>2.046261</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.357200</td>\n",
       "      <td>2.046261</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.089400</td>\n",
       "      <td>2.046261</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1         0.0020          0.01    0.9310\n",
      "1  4      8      0.1         0.0020          0.01    0.9280\n",
      "2  2      4      0.1         0.0020          0.01    0.9215\n",
      "3  8     16      0.1         0.0002          0.01    0.8990\n",
      "4  8     16      0.1         0.0020          0.01    0.9305\n",
      "5  8     16      0.1         0.0200          0.01    0.2955\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [2e-4, 2e-3, 2e-2]:\n",
    "    dropout = 0.1\n",
    "    r = 8\n",
    "    weight_decay = 0.01\n",
    "    alpha = 2 * r\n",
    "    config = create_lora_config(r, alpha, dropout)\n",
    "    model = create_lora_model(config)\n",
    "    trainer = create_trainer(model, learning_rate, weight_decay)\n",
    "\n",
    "    print(\"Start training a model with R={}, alpha={} droptout={}\".format(r, alpha, dropout))\n",
    "\n",
    "    trainer.train()\n",
    "    eval = trainer.evaluate()\n",
    "\n",
    "    accuracy = eval['eval_accuracy']\n",
    "    results.append({'r': r, 'alpha': alpha, 'dropout': dropout, 'learning_rate':learning_rate, 'weight_decay': weight_decay, 'accuracy': accuracy})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b515cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.222568</td>\n",
       "      <td>0.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>0.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.136879</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.117551</td>\n",
       "      <td>0.934500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16     0.10         0.0020          0.01    0.9310\n",
      "1  4      8     0.10         0.0020          0.01    0.9280\n",
      "2  2      4     0.10         0.0020          0.01    0.9215\n",
      "3  8     16     0.10         0.0002          0.01    0.8990\n",
      "4  8     16     0.10         0.0020          0.01    0.9305\n",
      "5  8     16     0.10         0.0200          0.01    0.2955\n",
      "6  8     16     0.01         0.0020          0.01    0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208435</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.148615</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.121173</td>\n",
       "      <td>0.930500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16     0.10         0.0020          0.01    0.9310\n",
      "1  4      8     0.10         0.0020          0.01    0.9280\n",
      "2  2      4     0.10         0.0020          0.01    0.9215\n",
      "3  8     16     0.10         0.0002          0.01    0.8990\n",
      "4  8     16     0.10         0.0020          0.01    0.9305\n",
      "5  8     16     0.10         0.0200          0.01    0.2955\n",
      "6  8     16     0.01         0.0020          0.01    0.9345\n",
      "7  8     16     0.10         0.0020          0.01    0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.224562</td>\n",
       "      <td>0.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.179373</td>\n",
       "      <td>0.924500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.133277</td>\n",
       "      <td>0.927000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16     0.10         0.0020          0.01    0.9310\n",
      "1  4      8     0.10         0.0020          0.01    0.9280\n",
      "2  2      4     0.10         0.0020          0.01    0.9215\n",
      "3  8     16     0.10         0.0002          0.01    0.8990\n",
      "4  8     16     0.10         0.0020          0.01    0.9305\n",
      "5  8     16     0.10         0.0200          0.01    0.2955\n",
      "6  8     16     0.01         0.0020          0.01    0.9345\n",
      "7  8     16     0.10         0.0020          0.01    0.9305\n",
      "8  8     16     0.50         0.0020          0.01    0.9270\n"
     ]
    }
   ],
   "source": [
    "for dropout in [0.01, 0.1, 0.5]:\n",
    "    learning_rate = 2e-3\n",
    "    r = 8\n",
    "    weight_decay = 0.01\n",
    "    alpha = 2 * r\n",
    "    config = create_lora_config(r, alpha, dropout)\n",
    "    model = create_lora_model(config)\n",
    "    trainer = create_trainer(model, learning_rate, weight_decay)\n",
    "\n",
    "    print(\"Start training a model with R={}, alpha={} droptout={}\".format(r, alpha, dropout))\n",
    "\n",
    "    trainer.train()\n",
    "    eval = trainer.evaluate()\n",
    "\n",
    "    accuracy = eval['eval_accuracy']\n",
    "    results.append({'r': r, 'alpha': alpha, 'dropout': dropout, 'learning_rate':learning_rate, 'weight_decay': weight_decay, 'accuracy': accuracy})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e96e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232432</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.167103</td>\n",
       "      <td>0.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.159356</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.125772</td>\n",
       "      <td>0.929500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16     0.10         0.0020         0.010    0.9310\n",
      "1  4      8     0.10         0.0020         0.010    0.9280\n",
      "2  2      4     0.10         0.0020         0.010    0.9215\n",
      "3  8     16     0.10         0.0002         0.010    0.8990\n",
      "4  8     16     0.10         0.0020         0.010    0.9305\n",
      "5  8     16     0.10         0.0200         0.010    0.2955\n",
      "6  8     16     0.01         0.0020         0.010    0.9345\n",
      "7  8     16     0.10         0.0020         0.010    0.9305\n",
      "8  8     16     0.50         0.0020         0.010    0.9270\n",
      "9  8     16     0.10         0.0020         0.001    0.9295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208435</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.148615</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.121173</td>\n",
       "      <td>0.930500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0   8     16     0.10         0.0020         0.010    0.9310\n",
      "1   4      8     0.10         0.0020         0.010    0.9280\n",
      "2   2      4     0.10         0.0020         0.010    0.9215\n",
      "3   8     16     0.10         0.0002         0.010    0.8990\n",
      "4   8     16     0.10         0.0020         0.010    0.9305\n",
      "5   8     16     0.10         0.0200         0.010    0.2955\n",
      "6   8     16     0.01         0.0020         0.010    0.9345\n",
      "7   8     16     0.10         0.0020         0.010    0.9305\n",
      "8   8     16     0.50         0.0020         0.010    0.9270\n",
      "9   8     16     0.10         0.0020         0.001    0.9295\n",
      "10  8     16     0.10         0.0020         0.010    0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>0.915500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.194819</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.143995</td>\n",
       "      <td>0.929500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.125075</td>\n",
       "      <td>0.935000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0   8     16     0.10         0.0020         0.010    0.9310\n",
      "1   4      8     0.10         0.0020         0.010    0.9280\n",
      "2   2      4     0.10         0.0020         0.010    0.9215\n",
      "3   8     16     0.10         0.0002         0.010    0.8990\n",
      "4   8     16     0.10         0.0020         0.010    0.9305\n",
      "5   8     16     0.10         0.0200         0.010    0.2955\n",
      "6   8     16     0.01         0.0020         0.010    0.9345\n",
      "7   8     16     0.10         0.0020         0.010    0.9305\n",
      "8   8     16     0.50         0.0020         0.010    0.9270\n",
      "9   8     16     0.10         0.0020         0.001    0.9295\n",
      "10  8     16     0.10         0.0020         0.010    0.9305\n",
      "11  8     16     0.10         0.0020         0.100    0.9350\n"
     ]
    }
   ],
   "source": [
    "for weight_decay in [0.001, 0.01, 0.1]:\n",
    "    learning_rate = 2e-3\n",
    "    dropout = 0.1\n",
    "    r = 8\n",
    "    alpha = 2 * r\n",
    "    config = create_lora_config(r, alpha, dropout)\n",
    "    model = create_lora_model(config)\n",
    "    trainer = create_trainer(model, learning_rate, weight_decay)\n",
    "\n",
    "    print(\"Start training a model with R={}, alpha={} droptout={}\".format(r, alpha, dropout))\n",
    "\n",
    "    trainer.train()\n",
    "    eval = trainer.evaluate()\n",
    "\n",
    "    accuracy = eval['eval_accuracy']\n",
    "    results.append({'r': r, 'alpha': alpha, 'dropout': dropout, 'learning_rate':learning_rate, 'weight_decay': weight_decay, 'accuracy': accuracy})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fc9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
