{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "* PEFT technique: LoRA\n",
    "* Model: GPT-2\n",
    "* Evaluation approach: Evaluate the pretrained model and the fine-tuned model with a test set and compare the result\n",
    "* Fine-tuning dataset: dair-ai/emotion from HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c4322b",
   "metadata": {},
   "source": [
    "### Load the datasdet dair-air/emotion and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f0fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModelForTokenClassification\n",
    "\n",
    "temp_path = \"/tmp\"\n",
    "save_path = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506ec15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "i feel the other person is unimportant but it is my interpretation see the trend that i have been misunderstood and that instead of wasting time hence the impatience part having them explain what i feel is already a misunderstanding i try to reexplain my intent : 0\n",
      "i actually thought i would feel bothered being their since ehb and the other woman ow spent quite a bit of time together there but i didnt feel much of anything : 3\n",
      "i feel the cold more than him : 3\n",
      "i always feel reassured after my appts : 1\n",
      "i moved into uni today and i feel so homesick and lonely and useless and part of mes saying fuck it go home and get a job and sod the degree : 0\n",
      "i can t believe all the newborns that i ve photographed with heads full of dark hair but i am feeling just a little envious because my babies are bald and blonde as they come : 3\n",
      "i kinda feel more relaxed with this blog than with the other one : 1\n",
      "i am feeling super excited as the weeks seem to be flying by and we are getting closer and closer to our due date : 1\n",
      "id love to hear how any of you handle these types of situations as well so if you have any stories of your own feel free to share : 1\n",
      "i feel like the projects that im successful in are projects that did not involve specific requirement free choice : 1\n",
      "\n",
      "Labels: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# print some random featues and the labels\n",
    "print(\"Features:\")\n",
    "indices = random.sample(range(len(ds[\"train\"])), 10)\n",
    "for i in indices:\n",
    "    print(\"{} : {}\".format(ds[\"train\"]['text'][i], ds[\"train\"]['label'][i]))\n",
    "\n",
    "print(\"\\nLabels: {}\".format(ds[\"train\"].features[\"label\"].names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
      "{'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}\n"
     ]
    }
   ],
   "source": [
    "# create data structures for further processing\n",
    "\n",
    "# names of the splits\n",
    "splits=list(ds.keys())\n",
    "# number of classes\n",
    "num_classes=len(ds[\"train\"].features[\"label\"].names)\n",
    "\n",
    "# Dictionairies to translate between label string and label number\n",
    "id2label = dict(zip(range(num_classes), ds['train'].features['label'].names))\n",
    "label2id = dict(zip(ds['train'].features['label'].names, range(num_classes)))\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d125f7",
   "metadata": {},
   "source": [
    "### Create a base model with added padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd66c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if hasattr(torch, \"accelerator\") else \"cuda\"\n",
    "\n",
    "# Create a base model variant with classification head\n",
    "def create_base_model(model_id):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_id, \n",
    "        num_labels=num_classes,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        device_map=device)\n",
    "    if model.config.pad_token_id is None:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Use GPT-2 as a small base model\n",
    "model_id = \"openai-community/gpt2\"\n",
    "model = create_base_model(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Add tokens to the dataset\n",
    "tokenized_ds = {}\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(\n",
    "        lambda x: tokenizer(x[\"text\"], truncation=True), batched=True\n",
    "    )\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add the padding token which is missing in GPT-2\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# metric function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [640/640 00:58, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.310627</td>\n",
       "      <td>0.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.241377</td>\n",
       "      <td>0.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.226692</td>\n",
       "      <td>0.542500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.334000</td>\n",
       "      <td>1.220351</td>\n",
       "      <td>0.544000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=640, training_loss=1.2996052742004394, metrics={'train_runtime': 58.6993, 'train_samples_per_second': 1090.302, 'train_steps_per_second': 10.903, 'total_flos': 1848843351244800.0, 'train_loss': 1.2996052742004394, 'epoch': 4.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2_classification\"\n",
    "checkpoint_dir = os.path.join(temp_path, model_name)\n",
    "save_dir_base = os.path.join(save_path, model_name)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=checkpoint_dir,\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=100,\n",
    "        per_device_eval_batch_size=100,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.220351219177246, 'eval_accuracy': 0.544, 'eval_runtime': 1.3128, 'eval_samples_per_second': 1523.444, 'eval_steps_per_second': 15.234, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "original_performance=trainer.evaluate()\n",
    "print(original_performance)\n",
    "\n",
    "model.save_pretrained(save_dir_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "Create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 594,432 || all params: 125,038,848 || trainable%: 0.4754\n"
     ]
    }
   ],
   "source": [
    "# Use Lora for PEFT\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    fan_in_fan_out=True,\n",
    ")\n",
    "\n",
    "# create PEFT model, use a fresh pretrained base model\n",
    "model_lora = get_peft_model(create_base_model(model_id), peft_config)\n",
    "model_lora.print_trainable_parameters()\n",
    "\n",
    "model_name = \"gpt2_classification_lora\"\n",
    "checkpoint_dir = os.path.join(temp_path, model_name)\n",
    "save_dir = os.path.join(save_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [640/640 01:51, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243477</td>\n",
       "      <td>0.908500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168843</td>\n",
       "      <td>0.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144285</td>\n",
       "      <td>0.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>0.125742</td>\n",
       "      <td>0.928500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=640, training_loss=0.2757429122924805, metrics={'train_runtime': 111.8946, 'train_samples_per_second': 571.967, 'train_steps_per_second': 5.72, 'total_flos': 1861763687424000.0, 'train_loss': 0.2757429122924805, 'epoch': 4.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_lora = Trainer(\n",
    "    model=model_lora,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=checkpoint_dir,\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=100,\n",
    "        per_device_eval_batch_size=100,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_lora.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  Save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_lora.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "Load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"openai-community/gpt2\"\n",
    "model_base = create_base_model(model_id)\n",
    "\n",
    "model_loaded = PeftModelForTokenClassification.from_pretrained(model_base, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_evaluate = Trainer(\n",
    "    model=model_loaded,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis_lora_evaluate\",\n",
    "        per_device_train_batch_size=100,\n",
    "        per_device_eval_batch_size=100,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "    ),\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "fine_tuned_performance=trainer_evaluate.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model: {'eval_loss': 0.1257418692111969, 'eval_model_preparation_time': 0.0019, 'eval_accuracy': 0.9285, 'eval_runtime': 1.4194, 'eval_samples_per_second': 1409.083, 'eval_steps_per_second': 14.091}\n",
      "Fine-Tuned Model accurcy:  0.9285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"Original Model:  \", original_performance)\n",
    "print(\"Fine-Tuned Model:\", fine_tuned_performance)\n",
    "\n",
    "#print(\"Original Model accurcy:   \", original_performance['eval_accuracy'])\n",
    "print(\"Fine-Tuned Model accurcy: \", fine_tuned_performance['eval_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e46c59",
   "metadata": {},
   "source": [
    "### Use different Quantization: QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "146c5c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 594,432 || all params: 125,038,848 || trainable%: 0.4754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 01:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248460</td>\n",
       "      <td>0.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.197286</td>\n",
       "      <td>0.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.146974</td>\n",
       "      <td>0.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>0.126689</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>0.120459</td>\n",
       "      <td>0.928500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"openai-community/gpt2\"\n",
    "temp_path = \"/tmp\"\n",
    "save_path = \"./data\"\n",
    "\n",
    "model_name = \"gpt2_classification_4bit_lora\"\n",
    "checkpoint_dir = os.path.join(temp_path, model_name)\n",
    "save_dir_base = os.path.join(save_path, model_name)\n",
    "\n",
    "model_id = \"openai-community/gpt2\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "model4b = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=num_classes,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    torch_dtype=\"auto\")\n",
    "\n",
    "model4b.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "for param in model4b.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# peft model\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    fan_in_fan_out=True,\n",
    ")\n",
    "\n",
    "model4bl = get_peft_model(model4b, peft_config)\n",
    "model4bl.print_trainable_parameters()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model4bl,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=checkpoint_dir,\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=100,\n",
    "        per_device_eval_batch_size=100,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        fp16=True\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "validation_lora_q4 = trainer.evaluate()\n",
    "#model4bl.save_pretrained(save_dire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c674ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model accuracy:          0.544\n",
      "Fine-Tuned Model accuracy:        0.9285\n",
      "Fine-Tuned Model 4 bit accuracy:  0.9285\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Model accuracy:         \", original_performance['eval_accuracy'])\n",
    "print(\"Fine-Tuned Model accuracy:       \", fine_tuned_performance['eval_accuracy'])\n",
    "print(\"Fine-Tuned Model 4 bit accuracy: \", validation_lora_q4['eval_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88eb0c",
   "metadata": {},
   "source": [
    "### Experiment with different LoRA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b74db434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lora_config(r, lora_alpha, lora_dropout):\n",
    "    peft_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        task_type=TaskType.TOKEN_CLS,\n",
    "        fan_in_fan_out=True,\n",
    "    )\n",
    "\n",
    "    return peft_config\n",
    "\n",
    "def create_lora_model(peft_config):\n",
    "    model_base = create_base_model(model_id)\n",
    "    model_lora = get_peft_model(model_base, peft_config)\n",
    "\n",
    "    return model_lora\n",
    "    \n",
    "def create_trainer(model, learning_rate, weight_decay):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir='/tmp',\n",
    "            per_device_train_batch_size=50,\n",
    "            per_device_eval_batch_size=50,\n",
    "            num_train_epochs=4,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "        ),\n",
    "        train_dataset=tokenized_ds[\"train\"],\n",
    "        eval_dataset=tokenized_ds[\"test\"],\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    return trainer\n",
    "\n",
    "def evaluate_model(model):\n",
    "    eval = model.evaluate()\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35e53326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:00, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.203967</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.164355</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.152113</td>\n",
       "      <td>0.929500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.131185</td>\n",
       "      <td>0.931000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1          0.002          0.01     0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=4, alpha=8 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.218007</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.167399</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.131540</td>\n",
       "      <td>0.928000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1          0.002          0.01     0.931\n",
      "1  4      8      0.1          0.002          0.01     0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=2, alpha=4 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243588</td>\n",
       "      <td>0.911500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.180413</td>\n",
       "      <td>0.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.171336</td>\n",
       "      <td>0.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.148653</td>\n",
       "      <td>0.921500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1          0.002          0.01    0.9310\n",
      "1  4      8      0.1          0.002          0.01    0.9280\n",
      "2  2      4      0.1          0.002          0.01    0.9215\n"
     ]
    }
   ],
   "source": [
    "for r in [8, 4, 2]:\n",
    "    dropout = 0.1\n",
    "    learning_rate = 2e-3\n",
    "    weight_decay = 0.01\n",
    "    alpha = 2 * r\n",
    "    config = create_lora_config(r, alpha, dropout)\n",
    "    model = create_lora_model(config)\n",
    "    trainer = create_trainer(model, learning_rate, weight_decay)\n",
    "\n",
    "    print(\"Start training a model with R={}, alpha={} droptout={}\".format(r, alpha, dropout))\n",
    "\n",
    "    trainer.train()\n",
    "    eval = trainer.evaluate()\n",
    "\n",
    "    accuracy = eval['eval_accuracy']\n",
    "    results.append({'r': r, 'alpha': alpha, 'dropout': dropout, 'learning_rate':learning_rate, 'weight_decay': weight_decay, 'accuracy': accuracy})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10ad3466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.514827</td>\n",
       "      <td>0.806500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.004500</td>\n",
       "      <td>0.336314</td>\n",
       "      <td>0.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.004500</td>\n",
       "      <td>0.292412</td>\n",
       "      <td>0.893500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.268815</td>\n",
       "      <td>0.899000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1         0.0020          0.01    0.9310\n",
      "1  4      8      0.1         0.0020          0.01    0.9280\n",
      "2  2      4      0.1         0.0020          0.01    0.9215\n",
      "3  8     16      0.1         0.0002          0.01    0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208435</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.148615</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.121173</td>\n",
       "      <td>0.930500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1         0.0020          0.01    0.9310\n",
      "1  4      8      0.1         0.0020          0.01    0.9280\n",
      "2  2      4      0.1         0.0020          0.01    0.9215\n",
      "3  8     16      0.1         0.0002          0.01    0.8990\n",
      "4  8     16      0.1         0.0020          0.01    0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.046261</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.357200</td>\n",
       "      <td>2.046261</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.357200</td>\n",
       "      <td>2.046261</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.089400</td>\n",
       "      <td>2.046261</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16      0.1         0.0020          0.01    0.9310\n",
      "1  4      8      0.1         0.0020          0.01    0.9280\n",
      "2  2      4      0.1         0.0020          0.01    0.9215\n",
      "3  8     16      0.1         0.0002          0.01    0.8990\n",
      "4  8     16      0.1         0.0020          0.01    0.9305\n",
      "5  8     16      0.1         0.0200          0.01    0.2955\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [2e-4, 2e-3, 2e-2]:\n",
    "    dropout = 0.1\n",
    "    r = 8\n",
    "    weight_decay = 0.01\n",
    "    alpha = 2 * r\n",
    "    config = create_lora_config(r, alpha, dropout)\n",
    "    model = create_lora_model(config)\n",
    "    trainer = create_trainer(model, learning_rate, weight_decay)\n",
    "\n",
    "    print(\"Start training a model with R={}, alpha={} droptout={}\".format(r, alpha, dropout))\n",
    "\n",
    "    trainer.train()\n",
    "    eval = trainer.evaluate()\n",
    "\n",
    "    accuracy = eval['eval_accuracy']\n",
    "    results.append({'r': r, 'alpha': alpha, 'dropout': dropout, 'learning_rate':learning_rate, 'weight_decay': weight_decay, 'accuracy': accuracy})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b515cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.222568</td>\n",
       "      <td>0.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>0.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.136879</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.117551</td>\n",
       "      <td>0.934500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16     0.10         0.0020          0.01    0.9310\n",
      "1  4      8     0.10         0.0020          0.01    0.9280\n",
      "2  2      4     0.10         0.0020          0.01    0.9215\n",
      "3  8     16     0.10         0.0002          0.01    0.8990\n",
      "4  8     16     0.10         0.0020          0.01    0.9305\n",
      "5  8     16     0.10         0.0200          0.01    0.2955\n",
      "6  8     16     0.01         0.0020          0.01    0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208435</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.148615</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.121173</td>\n",
       "      <td>0.930500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16     0.10         0.0020          0.01    0.9310\n",
      "1  4      8     0.10         0.0020          0.01    0.9280\n",
      "2  2      4     0.10         0.0020          0.01    0.9215\n",
      "3  8     16     0.10         0.0002          0.01    0.8990\n",
      "4  8     16     0.10         0.0020          0.01    0.9305\n",
      "5  8     16     0.10         0.0200          0.01    0.2955\n",
      "6  8     16     0.01         0.0020          0.01    0.9345\n",
      "7  8     16     0.10         0.0020          0.01    0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.224562</td>\n",
       "      <td>0.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.179373</td>\n",
       "      <td>0.924500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.133277</td>\n",
       "      <td>0.927000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16     0.10         0.0020          0.01    0.9310\n",
      "1  4      8     0.10         0.0020          0.01    0.9280\n",
      "2  2      4     0.10         0.0020          0.01    0.9215\n",
      "3  8     16     0.10         0.0002          0.01    0.8990\n",
      "4  8     16     0.10         0.0020          0.01    0.9305\n",
      "5  8     16     0.10         0.0200          0.01    0.2955\n",
      "6  8     16     0.01         0.0020          0.01    0.9345\n",
      "7  8     16     0.10         0.0020          0.01    0.9305\n",
      "8  8     16     0.50         0.0020          0.01    0.9270\n"
     ]
    }
   ],
   "source": [
    "for dropout in [0.01, 0.1, 0.5]:\n",
    "    learning_rate = 2e-3\n",
    "    r = 8\n",
    "    weight_decay = 0.01\n",
    "    alpha = 2 * r\n",
    "    config = create_lora_config(r, alpha, dropout)\n",
    "    model = create_lora_model(config)\n",
    "    trainer = create_trainer(model, learning_rate, weight_decay)\n",
    "\n",
    "    print(\"Start training a model with R={}, alpha={} droptout={}\".format(r, alpha, dropout))\n",
    "\n",
    "    trainer.train()\n",
    "    eval = trainer.evaluate()\n",
    "\n",
    "    accuracy = eval['eval_accuracy']\n",
    "    results.append({'r': r, 'alpha': alpha, 'dropout': dropout, 'learning_rate':learning_rate, 'weight_decay': weight_decay, 'accuracy': accuracy})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e96e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232432</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.167103</td>\n",
       "      <td>0.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.159356</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.125772</td>\n",
       "      <td>0.929500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ssd1/venv/lib/python3.12/site-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error 504 Server Error: Gateway Timeout for url: https://huggingface.co/openai-community/gpt2/resolve/main/config.json (Request ID: Root=1-689f7cfd-7fcc1919349fd5463984bb61;4c2b4273-282f-41dc-94be-96acd2fe946a)\n",
      "\n",
      "The request is taking longer than expected, please try again later. - silently ignoring the lookup for the file config.json in openai-community/gpt2.\n",
      "  warnings.warn(\n",
      "/media/ssd1/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in openai-community/gpt2 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0  8     16     0.10         0.0020         0.010    0.9310\n",
      "1  4      8     0.10         0.0020         0.010    0.9280\n",
      "2  2      4     0.10         0.0020         0.010    0.9215\n",
      "3  8     16     0.10         0.0002         0.010    0.8990\n",
      "4  8     16     0.10         0.0020         0.010    0.9305\n",
      "5  8     16     0.10         0.0200         0.010    0.2955\n",
      "6  8     16     0.01         0.0020         0.010    0.9345\n",
      "7  8     16     0.10         0.0020         0.010    0.9305\n",
      "8  8     16     0.50         0.0020         0.010    0.9270\n",
      "9  8     16     0.10         0.0020         0.001    0.9295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208435</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.148615</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.121173</td>\n",
       "      <td>0.930500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0   8     16     0.10         0.0020         0.010    0.9310\n",
      "1   4      8     0.10         0.0020         0.010    0.9280\n",
      "2   2      4     0.10         0.0020         0.010    0.9215\n",
      "3   8     16     0.10         0.0002         0.010    0.8990\n",
      "4   8     16     0.10         0.0020         0.010    0.9305\n",
      "5   8     16     0.10         0.0200         0.010    0.2955\n",
      "6   8     16     0.01         0.0020         0.010    0.9345\n",
      "7   8     16     0.10         0.0020         0.010    0.9305\n",
      "8   8     16     0.50         0.0020         0.010    0.9270\n",
      "9   8     16     0.10         0.0020         0.001    0.9295\n",
      "10  8     16     0.10         0.0020         0.010    0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training a model with R=8, alpha=16 droptout=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 01:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>0.915500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.194819</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.143995</td>\n",
       "      <td>0.929500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.125075</td>\n",
       "      <td>0.935000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    r  alpha  dropout  learning_rate  weight_decay  accuracy\n",
      "0   8     16     0.10         0.0020         0.010    0.9310\n",
      "1   4      8     0.10         0.0020         0.010    0.9280\n",
      "2   2      4     0.10         0.0020         0.010    0.9215\n",
      "3   8     16     0.10         0.0002         0.010    0.8990\n",
      "4   8     16     0.10         0.0020         0.010    0.9305\n",
      "5   8     16     0.10         0.0200         0.010    0.2955\n",
      "6   8     16     0.01         0.0020         0.010    0.9345\n",
      "7   8     16     0.10         0.0020         0.010    0.9305\n",
      "8   8     16     0.50         0.0020         0.010    0.9270\n",
      "9   8     16     0.10         0.0020         0.001    0.9295\n",
      "10  8     16     0.10         0.0020         0.010    0.9305\n",
      "11  8     16     0.10         0.0020         0.100    0.9350\n"
     ]
    }
   ],
   "source": [
    "for weight_decay in [0.001, 0.01, 0.1]:\n",
    "    learning_rate = 2e-3\n",
    "    dropout = 0.1\n",
    "    r = 8\n",
    "    alpha = 2 * r\n",
    "    config = create_lora_config(r, alpha, dropout)\n",
    "    model = create_lora_model(config)\n",
    "    trainer = create_trainer(model, learning_rate, weight_decay)\n",
    "\n",
    "    print(\"Start training a model with R={}, alpha={} droptout={}\".format(r, alpha, dropout))\n",
    "\n",
    "    trainer.train()\n",
    "    eval = trainer.evaluate()\n",
    "\n",
    "    accuracy = eval['eval_accuracy']\n",
    "    results.append({'r': r, 'alpha': alpha, 'dropout': dropout, 'learning_rate':learning_rate, 'weight_decay': weight_decay, 'accuracy': accuracy})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fc9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
